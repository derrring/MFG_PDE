name: CI/CD Pipeline
#
# Consolidated workflow combining quality, security, and performance checks
# Smart triggering: lightweight on PRs, comprehensive on releases
# Optimized for cost efficiency with manual fallback options
#

on:
  # Lightweight checks on PRs
  pull_request:
    paths:
      - 'mfg_pde/**/*.py'
      - 'tests/**/*.py'
      - 'pyproject.toml'
      - '.github/workflows/ci.yml'

  # Full checks on main branch pushes
  push:
    branches: [main]
    paths:
      - 'mfg_pde/**/*.py'
      - 'tests/**/*.py'
      - 'pyproject.toml'
      - '.github/workflows/ci.yml'

  # Comprehensive checks on releases
  release:
    types: [published]

  # Manual trigger for full validation
  workflow_dispatch:
    inputs:
      run_security_scan:
        description: 'Run comprehensive security scanning'
        required: false
        default: 'false'
        type: boolean
      run_performance_tests:
        description: 'Run performance regression tests'
        required: false
        default: 'true'
        type: boolean

env:
  PYTHON_VERSION: '3.12'
  CACHE_VERSION: v1

jobs:
  # === PHASE 0: Quick Validation (Fail Fast) ===
  quick-checks:
    name: Quick Validation (Syntax & Format)
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install minimal dependencies
      timeout-minutes: 2
      run: |
        python -m pip install --upgrade pip
        pip install ruff

    - name: Python syntax check (instant fail)
      timeout-minutes: 1
      run: |
        echo "Checking Python syntax..."
        find mfg_pde -name "*.py" -exec python -m py_compile {} +
        echo "âœ… Syntax valid"

    - name: Ruff format check (instant fail)
      timeout-minutes: 1
      run: |
        echo "Checking code formatting..."
        ruff format --check mfg_pde/
        echo "âœ… Formatting valid"

    - name: Ruff lint (critical errors only)
      timeout-minutes: 1
      run: |
        echo "Checking for critical lint errors (syntax & undefined names)..."
        ruff check --select F mfg_pde/
        echo "âœ… No critical errors"

  # === PHASE 1: Import Validation ===
  # Note: Ruff formatting, linting, and MyPy checks run in modern_quality.yml workflow
  import-validation:
    name: Import Validation
    runs-on: ubuntu-latest
    needs: quick-checks
    timeout-minutes: 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      timeout-minutes: 5
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Quick import test
      timeout-minutes: 1
      run: |
        echo "Testing package imports..."
        python -c "import mfg_pde; print('âœ… Package imports successfully')"

    - name: Documentation completeness check
      run: |
        echo "ðŸ“š Checking documentation completeness..."
        python -c "
        import ast
        from pathlib import Path

        def check_docstrings(file_path):
            with open(file_path, 'r') as f:
                tree = ast.parse(f.read())

            missing = []
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                    if not node.name.startswith('_'):  # Public only
                        if not ast.get_docstring(node):
                            missing.append(f'{file_path}:{node.lineno}:{node.name}')
            return missing

        all_missing = []
        for py_file in Path('mfg_pde').rglob('*.py'):
            if '__pycache__' not in str(py_file):
                missing = check_docstrings(py_file)
                all_missing.extend(missing)

        if all_missing:
            print('âš ï¸  Missing docstrings (tracked but not blocking):')
            for missing in all_missing[:5]:
                print(f'   {missing}')
            if len(all_missing) > 5:
                print(f'   ... and {len(all_missing) - 5} more')
        else:
            print('âœ… All public functions and classes have docstrings')
        "

  # === PHASE 2: Test Suite ===
  test-suite:
    name: Test Suite
    runs-on: ubuntu-latest
    needs: import-validation
    timeout-minutes: 40  # Increased for comprehensive test suite (1450+ tests)

    strategy:
      fail-fast: true  # Stop on first failure

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      timeout-minutes: 5
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Quick import test
      timeout-minutes: 1
      run: |
        echo "Testing package imports..."
        python -c "import mfg_pde; print('âœ… Package imports successfully')"

    - name: Run tests with coverage (skip slow tests on PRs)
      if: github.event_name != 'release'
      timeout-minutes: 30
      run: |
        # Note: test_backends/ and test_visualization/ excluded due to platform-specific failures
        # (MPS device tests on non-Mac, legacy plotting issues)
        pytest tests/ -v \
          --ignore=tests/unit/test_backends/ \
          --ignore=tests/unit/test_visualization/ \
          -m "not slow and not optional_torch and not benchmark and not experimental and not environment" \
          --cov=mfg_pde --cov-report=xml --cov-report=term --junitxml=junit.xml -o junit_family=legacy --maxfail=50 \
          --durations=20

    - name: Run all tests with coverage (including slow tests on releases)
      if: github.event_name == 'release'
      timeout-minutes: 35
      run: |
        pytest tests/ -v --cov=mfg_pde --cov-report=xml --cov-report=term --junitxml=junit.xml -o junit_family=legacy --maxfail=50 --durations=20

    - name: Upload coverage reports to Codecov
      if: ${{ !cancelled() }}
      uses: codecov/codecov-action@v5
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./coverage.xml
        fail_ci_if_error: false
        verbose: true

    - name: Upload test results to Codecov
      if: ${{ !cancelled() }}
      uses: codecov/test-results-action@v1
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./junit.xml
        fail_ci_if_error: false

  # === PHASE 3: Performance & Memory Validation ===
  performance-check:
    name: Performance & Memory Validation
    runs-on: ubuntu-latest
    needs: test-suite  # Wait for tests to pass before performance checks
    timeout-minutes: 15  # Timeout for performance checks
    if: ${{ github.event.inputs.run_performance_tests != 'false' }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      timeout-minutes: 5
      run: |
        python -m pip install --upgrade pip
        pip install -e .[performance]

    - name: Memory usage validation
      timeout-minutes: 10
      run: |
        echo "ðŸ§  Testing memory usage with controlled problem size..."
        python -c "
        import numpy as np
        from mfg_pde import MFGProblem
        from mfg_pde.core.mfg_components import MFGComponents
        from mfg_pde.geometry import TensorProductGrid
        from mfg_pde.geometry.boundary import no_flux_bc
        from mfg_pde.config import MFGSolverConfig
        from mfg_pde.alg.numerical.coupling import FixedPointIterator
        from mfg_pde.alg.numerical.fp_solvers import FPParticleSolver
        from mfg_pde.alg.numerical.hjb_solvers import HJBGFDMSolver
        from mfg_pde.core.hamiltonian import SeparableHamiltonian, QuadraticControlCost
        import psutil
        import os

        # Default Hamiltonian for tests (Issue #673)
        H = SeparableHamiltonian(
            control_cost=QuadraticControlCost(control_cost=1.0),
            coupling=lambda m: m,
            coupling_dm=lambda m: 1.0,
        )

        # Resource monitoring
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # Create problem with modern API (TensorProductGrid + explicit components)
        domain = TensorProductGrid(bounds=[(0.0, 1.0)], Nx_points=[26], boundary_conditions=no_flux_bc(dimension=1))
        components = MFGComponents(hamiltonian=H, m_initial=lambda x: np.exp(-10*(x-0.5)**2), u_final=lambda x: 0.0)
        problem = MFGProblem(geometry=domain, T=1.0, Nt=15, diffusion=0.5, components=components)

        # Create config
        config = MFGSolverConfig()

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_used = final_memory - initial_memory

        print('âœ… MFGProblem created successfully')
        print('âœ… MFGSolverConfig created successfully')
        print('âœ… All solver components importable')
        print(f'ðŸ§  Memory used: {memory_used:.1f} MB')
        print(f'ðŸ“Š Initial memory: {initial_memory:.1f} MB')
        print(f'ðŸ“Š Final memory: {final_memory:.1f} MB')

        if memory_used > 800:  # 800 MB threshold
            print(f'âŒ Excessive memory usage: {memory_used:.1f} MB')
            exit(1)
        else:
            print(f'âœ… Memory usage efficient: {memory_used:.1f} MB')
        "

    - name: Parameter migration system check
      run: |
        echo "ðŸ” Validating parameter migration system..."
        python -c "
        from mfg_pde.utils.parameter_migration import global_parameter_migrator
        print(f'âœ… Parameter migration system loaded with {len(global_parameter_migrator.mappings)} mappings')
        print('ðŸ“‹ Migration system operational for runtime parameter conversion')
        " || true

  # === PHASE 3: Security Scanning (Conditional) ===
  security-scan:
    name: Security Analysis
    runs-on: ubuntu-latest
    needs: import-validation
    timeout-minutes: 10  # Timeout for security scans
    if: ${{ github.event_name == 'release' || github.event.inputs.run_security_scan == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety pip-audit
        pip install -e .[dev]

    - name: Bandit security scan
      run: |
        echo "ðŸ”’ Running Bandit security analysis..."
        bandit -r mfg_pde/ -f json -o bandit-report.json || true
        bandit -r mfg_pde/ --severity-level medium --confidence-level medium
      continue-on-error: true

    - name: Dependency vulnerability check
      run: |
        echo "ðŸ”’ Checking dependencies for vulnerabilities..."
        safety check --json --output safety-report.json || true
        safety check --short-report
      continue-on-error: true

    - name: Comprehensive dependency audit
      run: |
        echo "ðŸ”’ Running comprehensive dependency audit..."
        pip-audit --format=json --output=pip-audit-report.json || true
        pip-audit --desc
      continue-on-error: true

    - name: Upload security reports
      uses: actions/upload-artifact@v6
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          pip-audit-report.json
        retention-days: 30

  # === PHASE 4: Integration Tests (Release Only) ===
  integration-tests:
    name: Integration Testing
    runs-on: ubuntu-latest
    needs: [import-validation, test-suite, performance-check]
    timeout-minutes: 30  # Timeout for integration tests (includes slow tests)
    if: ${{ github.event_name == 'release' || github.event_name == 'workflow_dispatch' }}

    strategy:
      matrix:
        python-version: ['3.12']  # Package requires Python >=3.12

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[test,performance]

    - name: Run integration tests
      run: |
        echo "ðŸ§ª Running integration tests for Python ${{ matrix.python-version }}..."
        python -c "
        import numpy as np
        from mfg_pde import MFGProblem
        from mfg_pde.core.mfg_components import MFGComponents
        from mfg_pde.geometry import TensorProductGrid
        from mfg_pde.geometry.boundary import no_flux_bc
        from mfg_pde.core.hamiltonian import SeparableHamiltonian, QuadraticControlCost
        import time

        # Default Hamiltonian for tests (Issue #673)
        H = SeparableHamiltonian(
            control_cost=QuadraticControlCost(control_cost=1.0),
            coupling=lambda m: m,
            coupling_dm=lambda m: 1.0,
        )

        # Create problem with modern API (TensorProductGrid + explicit components)
        domain = TensorProductGrid(bounds=[(0.0, 1.0)], Nx_points=[21], boundary_conditions=no_flux_bc(dimension=1))
        components = MFGComponents(hamiltonian=H, m_initial=lambda x: np.exp(-10*(x-0.5)**2), u_final=lambda x: 0.0)
        problem = MFGProblem(geometry=domain, T=1.0, Nt=10, diffusion=0.5, components=components)

        # Test problem.solve() API
        print('Testing problem.solve() API...')
        start_time = time.time()
        result = problem.solve()
        duration = time.time() - start_time
        print(f'  âœ… problem.solve(): {duration:.2f}s')

        print('ðŸŽ‰ All integration tests passed!')
        "

  # === PHASE 5: Build Validation (Release Only) ===
  build-validation:
    name: Build & Distribution
    runs-on: ubuntu-latest
    needs: [import-validation, test-suite, performance-check]
    timeout-minutes: 15  # Timeout for build validation
    if: ${{ github.event_name == 'release' }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install build tools
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: Build distribution
      run: |
        echo "ðŸ“¦ Building distribution packages..."
        python -m build

    - name: Validate distribution
      run: |
        echo "ðŸ” Validating distribution packages..."
        twine check dist/*

    - name: Test installation from built package
      run: |
        echo "ðŸ§ª Testing installation from built package..."
        pip install dist/*.whl
        python -c "
        import numpy as np
        import mfg_pde
        print(f'âœ… Successfully imported mfg_pde version {mfg_pde.__version__}')

        # Quick smoke test with modern API (TensorProductGrid + explicit components)
        from mfg_pde import MFGProblem
        from mfg_pde.core.mfg_components import MFGComponents
        from mfg_pde.geometry import TensorProductGrid
        from mfg_pde.geometry.boundary import no_flux_bc
        from mfg_pde.core.hamiltonian import SeparableHamiltonian, QuadraticControlCost
        H = SeparableHamiltonian(
            control_cost=QuadraticControlCost(control_cost=1.0),
            coupling=lambda m: m,
            coupling_dm=lambda m: 1.0,
        )
        domain = TensorProductGrid(bounds=[(0.0, 1.0)], Nx_points=[11], boundary_conditions=no_flux_bc(dimension=1))
        components = MFGComponents(hamiltonian=H, m_initial=lambda x: np.exp(-10*(x-0.5)**2), u_final=lambda x: 0.0)
        problem = MFGProblem(geometry=domain, T=1.0, Nt=5, diffusion=0.5, components=components)
        result = problem.solve()
        print('âœ… Package installation and basic functionality verified')
        "

    - name: Upload build artifacts
      uses: actions/upload-artifact@v6
      with:
        name: distribution-packages
        path: dist/
        retention-days: 30

  # === PHASE 6: Summary Report ===
  ci-summary:
    name: CI/CD Summary
    runs-on: ubuntu-latest
    needs: [import-validation, test-suite, performance-check]
    if: always()

    steps:
    - name: Generate CI summary
      run: |
        echo "# ðŸš€ MFG_PDE CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Build Information" >> $GITHUB_STEP_SUMMARY
        echo "- **Event**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Python Version**: ${{ env.PYTHON_VERSION }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Quality Gates" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… **Code Quality**: Ruff formatting and linting" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… **Type Safety**: Mypy type checking" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… **Performance**: Memory and execution validation" >> $GITHUB_STEP_SUMMARY

        if [[ "${{ github.event_name }}" == "release" || "${{ github.event.inputs.run_security_scan }}" == "true" ]]; then
          echo "- âœ… **Security**: Comprehensive scanning completed" >> $GITHUB_STEP_SUMMARY
        else
          echo "- â­ï¸ **Security**: Skipped (not a release)" >> $GITHUB_STEP_SUMMARY
        fi

        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Modern Tooling Benefits" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸš€ **10-100x faster** than legacy multi-tool workflows" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ”§ **Unified configuration** in pyproject.toml" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸŽ¯ **Smart triggering** optimized for cost efficiency" >> $GITHUB_STEP_SUMMARY
        echo "- ðŸ“Š **Comprehensive reporting** with actionable insights" >> $GITHUB_STEP_SUMMARY
