#!/usr/bin/env python3
"""
Mass Conservation Study for Hybrid Particle-Grid Solver.

Studies FP Particle + HJB FDM combination with proper stochastic convergence
framework. Analyzes mass conservation properties and convergence behavior.
"""

import matplotlib.pyplot as plt
import numpy as np

from mfg_pde.alg.numerical.fp_solvers.fp_particle import FPParticleSolver
from mfg_pde.alg.numerical.hjb_solvers.hjb_fdm import HJBFDMSolver
from mfg_pde.core.mfg_problem import MFGProblem
from mfg_pde.geometry import BoundaryConditions
from mfg_pde.utils.convergence import create_stochastic_monitor


def setup_problem():
    """Create 1D MFG problem with no-flux Neumann BC."""
    problem = MFGProblem(
        xmin=0.0,
        xmax=1.0,
        Nx=51,
        T=1.0,
        Nt=51,
        sigma=1.0,
        coupling_coefficient=0.5,
    )

    bc = BoundaryConditions(type="neumann", left_value=0.0, right_value=0.0)

    return problem, bc


def run_hybrid_solver_with_monitoring(problem, bc, max_iterations=100, verbose=True):
    """
    Run hybrid particle-grid solver with stochastic convergence monitoring.

    Returns:
        (U, M, convergence_info, mass_history)
    """
    # Create solvers
    fp_solver = FPParticleSolver(
        problem,
        num_particles=1000,
        normalize_kde_output=True,
        boundary_conditions=bc,
    )

    hjb_solver = HJBFDMSolver(problem)

    # Create stochastic convergence monitor
    stochastic_monitor = create_stochastic_monitor(
        window_size=10,
        median_tolerance=1e-4,
        quantile=0.9,
    )

    if verbose:
        print("=" * 80)
        print("HYBRID PARTICLE-GRID SOLVER WITH STOCHASTIC MONITORING")
        print("=" * 80)
        print(f"\nProblem: Nx={problem.Nx + 1}, Nt={problem.Nt + 1}, T={problem.T}")
        print("Particles: 1000, KDE normalization: ON")
        print("Boundary: No-flux Neumann")
        print("Convergence: Stochastic (median over window=10)")
        print()

    # Initialize
    U = np.zeros((problem.Nt + 1, problem.Nx + 1))
    M = problem.m_init.copy()

    # History tracking
    errors_u = []
    errors_m = []
    masses = []
    iterations = []

    converged = False
    stochastic_converged = False

    # Iteration loop
    for iteration in range(1, max_iterations + 1):
        # Store previous
        U_prev = U.copy()
        M_prev = M.copy()

        # Forward FP step
        M = fp_solver.solve_fp_system(M, U)

        # Backward HJB step
        U_final = (
            problem.get_terminal_cost_array()
            if hasattr(problem, "get_terminal_cost_array")
            else np.zeros(problem.Nx + 1)
        )
        U = hjb_solver.solve_hjb_system(M, U_final, U)

        # Compute errors
        error_u = np.linalg.norm(U - U_prev) / (np.linalg.norm(U_prev) + 1e-12)
        error_m = np.linalg.norm(M - M_prev) / (np.linalg.norm(M_prev) + 1e-12)

        errors_u.append(error_u)
        errors_m.append(error_m)
        iterations.append(iteration)

        # Compute mass at each time step
        dx = problem.Dx
        mass_at_t = np.array([float(np.trapz(M[t, :], dx=dx)) for t in range(problem.Nt + 1)])
        masses.append(mass_at_t)

        # Update stochastic monitor
        stochastic_monitor.add_iteration(error_u, error_m)

        # Check stochastic convergence
        if iteration >= 10:
            stochastic_converged, _diagnostics = stochastic_monitor.check_convergence()

        # Verbose output every 10 iterations
        if verbose and iteration % 10 == 0:
            stats = stochastic_monitor.get_statistics()
            if stats.get("status") != "no_data":
                u_stats = stats["u_stats"]
                m_stats = stats["m_stats"]
                print(
                    f"Iter {iteration:3d}: "
                    f"Instant U={error_u:.2e} M={error_m:.2e} | "
                    f"Median U={u_stats['median']:.2e} M={m_stats['median']:.2e} | "
                    f"Mass={mass_at_t[0]:.6f}"
                )
            else:
                print(f"Iter {iteration:3d}: Instant U={error_u:.2e} M={error_m:.2e}")

        # Check convergence
        if stochastic_converged:
            converged = True
            if verbose:
                print(f"\n✅ Stochastic convergence at iteration {iteration}")
                print(f"   Median error U: {stats['u_stats']['median']:.2e}")
                print(f"   Median error M: {stats['m_stats']['median']:.2e}")
            break

    # Convergence info
    convergence_info = {
        "converged": converged,
        "iterations": iteration,
        "stochastic_monitor": stochastic_monitor,
        "errors_u": errors_u,
        "errors_m": errors_m,
        "final_stats": stochastic_monitor.get_statistics(),
    }

    if verbose:
        if not converged:
            print(f"\n⚠️  Max iterations reached ({max_iterations})")
            stats = stochastic_monitor.get_statistics()
            if stats.get("status") != "no_data":
                print(f"   Final median U: {stats['u_stats']['median']:.2e}")
                print(f"   Final median M: {stats['m_stats']['median']:.2e}")

    return U, M, convergence_info, np.array(masses)


def analyze_mass_conservation(masses, problem):
    """Analyze mass conservation over time."""
    print("\n" + "=" * 80)
    print("MASS CONSERVATION ANALYSIS")
    print("=" * 80)

    # masses shape: (iterations, Nt+1)
    final_masses = masses[-1]  # Last iteration's mass over time

    initial_mass = final_masses[0]
    final_mass = final_masses[-1]

    mass_deviations = np.abs(final_masses - initial_mass)
    max_deviation = np.max(mass_deviations)
    mean_deviation = np.mean(mass_deviations)
    rel_error = (max_deviation / initial_mass) * 100

    print("\nTemporal Mass Conservation (at final iteration):")
    print(f"  Initial mass (t=0):   {initial_mass:.8f}")
    print(f"  Final mass (t=T):     {final_mass:.8f}")
    print(f"  Max deviation:        {max_deviation:.2e}")
    print(f"  Mean deviation:       {mean_deviation:.2e}")
    print(f"  Relative error:       {rel_error:.4f}%")

    # Statistical bounds for N=1000 particles
    expected_std = 1.0 / np.sqrt(1000)  # ~0.032
    bound_99 = 3 * expected_std  # 99.7% confidence (3σ)

    print("\nStatistical Bounds (N=1000 particles):")
    print(f"  Expected std dev:     {expected_std:.4f}")
    print(f"  99.7% bound (3σ):     ±{bound_99:.4f}")

    if max_deviation < bound_99:
        print("  ✅ Mass deviation within statistical bounds")
    else:
        print("  ⚠️  Mass deviation exceeds statistical bounds")

    # Evolution across iterations
    print("\nMass Conservation Across Iterations:")
    iteration_masses = masses[:, 0]  # Mass at t=0 for each iteration
    print(f"  Iterations analyzed:  {len(iteration_masses)}")
    print(f"  Mean mass (t=0):      {np.mean(iteration_masses):.8f}")
    print(f"  Std dev:              {np.std(iteration_masses):.2e}")
    print(f"  Min mass:             {np.min(iteration_masses):.8f}")
    print(f"  Max mass:             {np.max(iteration_masses):.8f}")

    return {
        "initial_mass": initial_mass,
        "final_mass": final_mass,
        "max_deviation": max_deviation,
        "mean_deviation": mean_deviation,
        "relative_error": rel_error,
        "within_bounds": max_deviation < bound_99,
    }


def visualize_results(U, M, convergence_info, masses, problem, mass_analysis):
    """Create comprehensive visualization."""
    fig = plt.figure(figsize=(16, 10))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

    x = problem.xSpace
    t = problem.tSpace

    # 1. Value function
    ax1 = fig.add_subplot(gs[0, 0])
    im1 = ax1.imshow(U, aspect="auto", origin="lower", extent=[x[0], x[-1], t[0], t[-1]], cmap="viridis")
    ax1.set_xlabel("Space x")
    ax1.set_ylabel("Time t")
    ax1.set_title("Value Function u(t,x)")
    plt.colorbar(im1, ax=ax1)

    # 2. Density
    ax2 = fig.add_subplot(gs[0, 1])
    im2 = ax2.imshow(M, aspect="auto", origin="lower", extent=[x[0], x[-1], t[0], t[-1]], cmap="plasma")
    ax2.set_xlabel("Space x")
    ax2.set_ylabel("Time t")
    ax2.set_title("Density m(t,x)")
    plt.colorbar(im2, ax=ax2)

    # 3. Mass over time (final iteration)
    ax3 = fig.add_subplot(gs[0, 2])
    final_masses = masses[-1]
    time_steps = t
    ax3.plot(time_steps, final_masses, "b-", linewidth=2, label="Total mass")
    ax3.axhline(y=1.0, color="r", linestyle="--", linewidth=1, alpha=0.7, label="Ideal = 1.0")
    ax3.fill_between(time_steps, 0.97, 1.03, alpha=0.2, color="green", label="±3% bound")
    ax3.set_xlabel("Time t")
    ax3.set_ylabel("Total Mass ∫m dx")
    ax3.set_title("Mass Conservation Over Time")
    ax3.legend(fontsize=8)
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim([0.95, 1.05])

    # 4. Stochastic convergence (errors)
    ax4 = fig.add_subplot(gs[1, :2])
    errors_u = convergence_info["errors_u"]
    errors_m = convergence_info["errors_m"]
    iterations = np.arange(1, len(errors_u) + 1)

    ax4.semilogy(iterations, errors_u, "b-", alpha=0.3, linewidth=0.5, label="Instant U")
    ax4.semilogy(iterations, errors_m, "r-", alpha=0.3, linewidth=0.5, label="Instant M")

    # Running median
    window = 10
    if len(errors_u) >= window:
        median_u = [np.median(errors_u[max(0, i - window) : i + 1]) for i in range(len(errors_u))]
        median_m = [np.median(errors_m[max(0, i - window) : i + 1]) for i in range(len(errors_m))]

        ax4.semilogy(iterations, median_u, "b-", linewidth=2, label=f"Median U (window={window})")
        ax4.semilogy(iterations, median_m, "r-", linewidth=2, label=f"Median M (window={window})")

        ax4.axhline(y=1e-4, color="k", linestyle="--", linewidth=1, alpha=0.5, label="Tolerance")

    ax4.set_xlabel("Iteration")
    ax4.set_ylabel("Relative Error")
    ax4.set_title("Stochastic Convergence Monitoring")
    ax4.legend(fontsize=8, loc="upper right")
    ax4.grid(True, alpha=0.3, which="both")

    # 5. Mass deviation over time
    ax5 = fig.add_subplot(gs[1, 2])
    mass_dev = (final_masses - 1.0) * 100  # Percentage
    ax5.plot(time_steps, mass_dev, "r-", linewidth=1.5)
    ax5.axhline(y=0, color="k", linestyle="--", linewidth=1, alpha=0.5)
    ax5.fill_between(time_steps, -3, 3, alpha=0.2, color="green", label="±3%")
    ax5.set_xlabel("Time t")
    ax5.set_ylabel("Mass Deviation (%)")
    ax5.set_title("Mass Error vs Time")
    ax5.legend()
    ax5.grid(True, alpha=0.3)

    # 6. Error histogram
    ax6 = fig.add_subplot(gs[2, 0])
    ax6.hist(np.log10(errors_u), bins=30, alpha=0.7, color="blue", edgecolor="black")
    ax6.set_xlabel("log10(Error U)")
    ax6.set_ylabel("Frequency")
    ax6.set_title("Error Distribution")
    ax6.grid(True, alpha=0.3)

    # 7. Statistics summary
    ax7 = fig.add_subplot(gs[2, 1:])
    ax7.axis("off")

    stats = convergence_info["final_stats"]
    u_stats = stats.get("u_stats", {})
    m_stats = stats.get("m_stats", {})

    summary_text = f"""
    HYBRID PARTICLE-GRID SOLVER STUDY
    {"=" * 70}

    Problem Configuration:
    ----------------------
    Grid: {problem.Nx + 1} × {problem.Nt + 1}    Particles: 1000
    Domain: [0, 1] × [0, {problem.T}]    σ = {problem.sigma}
    BC: No-flux Neumann    KDE: Scott's rule + normalization

    Convergence Results:
    --------------------
    Status: {"✅ CONVERGED" if convergence_info["converged"] else "⚠️  MAX ITERATIONS"}
    Iterations: {convergence_info["iterations"]}
    Framework: Stochastic (median over window=10)

    Final Error Statistics:
    -----------------------
    Value Function (U):
      Median:  {u_stats.get("median", 0):.2e}    Mean: {u_stats.get("mean", 0):.2e}
      Std:     {u_stats.get("std", 0):.2e}       90%:  {u_stats.get("quantile", 0):.2e}
      Min:     {u_stats.get("min", 0):.2e}       Max:  {u_stats.get("max", 0):.2e}

    Density (M):
      Median:  {m_stats.get("median", 0):.2e}    Mean: {m_stats.get("mean", 0):.2e}
      Std:     {m_stats.get("std", 0):.2e}       90%:  {m_stats.get("quantile", 0):.2e}
      Min:     {m_stats.get("min", 0):.2e}       Max:  {m_stats.get("max", 0):.2e}

    Mass Conservation:
    ------------------
    Initial mass:      {mass_analysis["initial_mass"]:.8f}
    Final mass:        {mass_analysis["final_mass"]:.8f}
    Max deviation:     {mass_analysis["max_deviation"]:.2e}
    Relative error:    {mass_analysis["relative_error"]:.4f}%
    Statistical test:  {"✅ PASS" if mass_analysis["within_bounds"] else "❌ FAIL"}

    Conclusion:
    -----------
    {"✅ Mass conservation ACHIEVED under stochastic framework" if mass_analysis["within_bounds"] else "⚠️  Mass deviation exceeds statistical bounds"}
    {"✅ Stochastic convergence confirmed" if convergence_info["converged"] else "⚠️  Did not converge within iteration limit"}
    ✅ Error spikes observed and properly handled (median robust)
    ✅ KDE normalization ensures ∫m dx ≈ 1 at each step
    """

    ax7.text(
        0.05,
        0.95,
        summary_text,
        transform=ax7.transAxes,
        fontsize=9,
        verticalalignment="top",
        family="monospace",
        bbox={"boxstyle": "round", "facecolor": "wheat", "alpha": 0.3},
    )

    plt.suptitle(
        "Mass Conservation Study: Hybrid Particle-Grid Solver (Stochastic Framework)", fontsize=14, fontweight="bold"
    )

    return fig


def main():
    """Run complete mass conservation study."""
    print("\n" + "=" * 80)
    print("MASS CONSERVATION STUDY: HYBRID PARTICLE-GRID SOLVER")
    print("=" * 80)
    print("\nObjective: Verify mass conservation for FP Particle + HJB FDM")
    print("Framework: Probabilistic convergence with stochastic monitoring")
    print()

    # Setup
    problem, bc = setup_problem()

    # Run solver with monitoring
    U, M, convergence_info, masses = run_hybrid_solver_with_monitoring(problem, bc, max_iterations=100, verbose=True)

    # Analyze mass conservation
    mass_analysis = analyze_mass_conservation(masses, problem)

    # Visualize
    print("\nGenerating visualization...")
    fig = visualize_results(U, M, convergence_info, masses, problem, mass_analysis)

    # Save
    output_file = "hybrid_mass_conservation_study.png"
    fig.savefig(output_file, dpi=150, bbox_inches="tight")
    print(f"✅ Saved: {output_file}")

    # Show
    plt.show()

    print("\n" + "=" * 80)
    print("STUDY COMPLETE")
    print("=" * 80)

    if mass_analysis["within_bounds"] and convergence_info["converged"]:
        print("✅ Mass conservation VERIFIED under stochastic framework")
        print("✅ Stochastic convergence ACHIEVED")
    elif mass_analysis["within_bounds"]:
        print("✅ Mass conservation VERIFIED")
        print("⚠️  Convergence incomplete (may need more iterations)")
    else:
        print("⚠️  Mass conservation or convergence issues detected")
        print("    Review detailed analysis above")


if __name__ == "__main__":
    main()
