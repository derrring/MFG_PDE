mfg_pde/utils/numerical/functional_calculus.py:    use_jax: bool = False  # Use JAX for automatic differentiation
mfg_pde/utils/numerical/functional_calculus.py:    use_pytorch: bool = False  # Use PyTorch for automatic differentiation
mfg_pde/utils/numerical/mcmc.py:    step_size_adaptation: bool = True  # Dual averaging for step size
mfg_pde/utils/functional_calculus.py:    use_jax: bool = False  # Use JAX for automatic differentiation
mfg_pde/utils/functional_calculus.py:    use_pytorch: bool = False  # Use PyTorch for automatic differentiation
mfg_pde/alg/optimization/optimal_transport/sinkhorn_solver.py:    log_domain: bool = True  # Use log-domain Sinkhorn for numerical stability
mfg_pde/alg/neural/operator_learning/deeponet.py:        use_batch_norm: bool = False  # Use batch normalization
mfg_pde/alg/neural/operator_learning/deeponet.py:        use_layer_norm: bool = True  # Use layer normalization
mfg_pde/alg/neural/operator_learning/deeponet.py:        use_bias_net: bool = True  # Use bias network
