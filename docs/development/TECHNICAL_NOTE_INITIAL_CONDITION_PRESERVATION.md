# Technical Note: Initial Condition Preservation in Particle-Based MFG Solvers

**Date**: 2025-10-05
**Status**: ✅ RESOLVED
**Issue**: Initial condition violation in iterative particle-based FP solvers
**Solution**: Explicit enforcement of temporal boundary condition

---

## Executive Summary

**Problem**: Particle-based Fokker-Planck (FP) solvers use Kernel Density Estimation (KDE) to reconstruct density from particles. This introduces approximation error that violates the exact initial condition `m(0, x) = m₀(x)`, especially when combined with Picard damping.

**Solution**: Treat the initial condition as a **boundary condition in time** and explicitly restore `M[0, :] = m_init` after each iteration that updates M.

**Impact**: Zero error in initial condition (machine precision), all 16 mathematical mass conservation tests passing.

---

## Mathematical Background

### MFG System

Mean Field Games solve a coupled PDE system:

**Hamilton-Jacobi-Bellman (HJB)** - backward in time:
```
-∂u/∂t + H(x, ∇u, m) = 0    in [0,T] × Ω
u(T, x) = g(x)                (terminal condition)
```

**Fokker-Planck (FP)** - forward in time:
```
∂m/∂t - σ²Δm + div(m·∇H_p) = 0    in [0,T] × Ω
m(0, x) = m₀(x)                     (initial condition)
```

### Iterative Fixed-Point Scheme

Standard solution approach:

1. Initialize: `M^0 = m₀`, `U^0 = 0`
2. For k = 0, 1, 2, ...:
   - Solve HJB with `m = M^k` → get `U^(k+1)`
   - Solve FP with `u = U^(k+1)` → get `M^(k+1)`
   - Apply damping: `M^(k+1) ← θ·M_new + (1-θ)·M^k`
   - Check convergence

**Critical observation**: Step 3 modifies **all** time slices `M[t, :]` for `t = 0, 1, ..., Nt`, including the initial condition at `t=0`.

---

## The Phenomenon: Why Initial Conditions Get Violated

### Particle-Based FP Solver Workflow

```python
def solve_fp_system(self, m_initial_condition: np.ndarray, U: np.ndarray) -> np.ndarray:
    """
    Solve FP equation using particle method.

    Args:
        m_initial_condition: Exact initial density m₀(x)
        U: Value function for drift computation

    Returns:
        M_density: Reconstructed density on grid (Nt, Nx)
    """
    # Step 1: Sample particles from initial distribution
    particles_t0 = np.random.choice(
        x_grid,
        size=num_particles,
        p=m_initial_condition * dx / np.sum(m_initial_condition * dx)
    )

    # Step 2: Reconstruct initial density via KDE
    M[0, :] = KDE(particles_t0, bandwidth=h)  # ← Approximation!

    # Step 3: Evolve particles via SDE
    for t in range(Nt):
        drift = -gradient(U[t, :])
        particles[t+1] = particles[t] + drift * dt + sigma * sqrt(dt) * noise
        M[t+1, :] = KDE(particles[t+1], bandwidth=h)

    return M
```

### Sources of Error in `M[0, :]`

1. **Sampling Error**:
   - Finite particles (e.g., 5000) cannot perfectly represent continuous `m₀(x)`
   - Monte Carlo error scales as `O(1/√N_particles)`
   - Example: Gaussian `m₀` with few particles → bumpy histogram

2. **KDE Bandwidth Smoothing**:
   - KDE uses kernel: `K_h(x) = (1/h)·K((x-x_i)/h)`
   - Smooths out sharp features in `m₀(x)`
   - Exact reconstruction requires `h → 0` and `N → ∞`

3. **Boundary Effects**:
   - KDE has edge artifacts near `x_min`, `x_max`
   - Truncation bias at domain boundaries
   - Renormalization changes density shape

### Numerical Example

```python
# Problem: Gaussian initial condition on [0, 2]
m_init = exp(-50*(x - 1)^2)  # Sharp Gaussian centered at x=1

# Exact values at grid points
m_init = [1.76e-03, 7.10e-01, 5.24e+00, 7.10e-01, 1.76e-03, ...]
sum(m_init * dx) = 1.0000  # Normalized

# After particle sampling (5000 particles) + KDE reconstruction
M_kde[0, :] = [8.78e-02, 1.16e+00, 4.13e+00, 1.20e+00, 9.49e-02, ...]
sum(M_kde[0, :] * dx) = 0.9987  # Close but not exact

# Pointwise errors
max_error = |m_init - M_kde[0, :]|_∞ = 1.11  # 21% relative error!
mean_error = |m_init - M_kde[0, :]|_1 = 0.31  # 6% average error
```

### Compounded by Damping

After Picard damping with `θ = 0.7`:

```python
# Iteration k
M_old[0, :] = [previous KDE approximation]

# FP solve
M_new[0, :] = [new KDE approximation]  # Different random particles!

# Damping
M[0, :] = 0.7 * M_new[0, :] + 0.3 * M_old[0, :]
# Now M[0, :] is weighted average of TWO KDE approximations
# Error accumulates over iterations!
```

**Result**: `M[0, :]` drifts further from exact `m_init` with each iteration.

---

## The Solution: Explicit Enforcement

### Mathematical Principle

**Key Insight**: The initial condition `m(0, x) = m₀(x)` is a **boundary condition in time**.

Just as we enforce spatial boundary conditions:
- Dirichlet: `m(t, x=0) = m_left`
- Neumann: `∂m/∂n(t, x=∂Ω) = flux`
- Periodic: `m(t, x=0) = m(t, x=L)`

We must enforce temporal boundary condition:
- **Initial**: `m(0, x) = m₀(x)`

**Theorem**: For the FP equation with IC `m(0, ·) = m₀`, the solution satisfies this condition **exactly** for all numerical approximations of `t > 0`.

**Corollary**: Any numerical scheme must preserve `M[0, :] = m_init` exactly, independent of the approximation method used.

### Implementation

Add explicit restoration after any update to M:

```python
# After damping
self.M = damping_factor * M_new + (1 - damping_factor) * M_old

# Preserve initial condition (boundary condition in time)
# The damping step above may modify M[0, :], but initial condition is fixed
initial_m_dist = self.problem.get_initial_m()
self.M[0, :] = initial_m_dist
```

### Where to Apply

**Location 1**: `config_aware_fixed_point_iterator.py:194-200`

```python
# Apply damping to M
self.M = solve_config.picard.damping_factor * M_new_tmp + (1 - solve_config.picard.damping_factor) * M_old

# Preserve initial condition (boundary condition in time)
# The damping step above may modify M[0,:], but initial condition is fixed
initial_m_dist = self.problem.get_initial_m() if hasattr(self.problem, "get_initial_m") else np.ones(Nx)
self.M[0, :] = initial_m_dist
```

**Location 2**: `fixed_point_iterator.py:308-318`

```python
# Apply damping and/or Anderson acceleration
if self.use_anderson and self.anderson_accelerator is not None:
    # Anderson for U only, standard damping for M
    self.U = anderson_accelerated_U
    self.M = M_damped
else:
    # Standard damping for both
    self.U = self.thetaUM * U_new + (1 - self.thetaUM) * U_old
    self.M = self.thetaUM * M_new + (1 - self.thetaUM) * M_old

# Preserve initial condition (boundary condition in time)
# The damping/Anderson steps above may modify M[0,:], but initial condition is fixed
self.M[0, :] = initial_m_dist
```

---

## Why This Is Correct

### Mass Conservation

**Question**: Does forcing `M[0, :] = m_init` violate mass conservation?

**Answer**: **No** - it ensures correct mass!

The mass conservation property states:
```
∫ m(t, x) dx = ∫ m₀(x) dx = constant    for all t ≥ 0
```

**Analysis**:
- Exact `m_init` has total mass: `∫ m₀ dx = M_total`
- KDE approximation has mass: `∫ M_kde[0, :] dx ≈ M_total` (close but not exact)
- Enforcing `M[0, :] = m_init` **guarantees** exact mass at `t=0`
- Particle methods preserve mass approximately at `t > 0`

**Verification**:

```python
# Before fix
initial_mass = np.sum(M_kde[0, :]) * dx  # 0.9987 (KDE approximation)
final_mass = np.sum(M[-1, :]) * dx        # 0.9991 (particle evolution)
# Mass "conserved" to 99.87% → Wrong reference!

# After fix
initial_mass = np.sum(m_init) * dx        # 1.0000 (exact by definition)
final_mass = np.sum(M[-1, :]) * dx        # 0.9996 (particle approximation)
# Mass conserved to 99.96% → Correct reference!
```

### Convergence

**Question**: Does this interfere with Picard convergence?

**Answer**: **No** - it enforces the correct fixed point!

The MFG fixed point satisfies:
```
M* = FP_solve(U*, m₀)
U* = HJB_solve(M*, g)
```

where `FP_solve(U, m₀)` must satisfy `M[0, :] = m₀` **by definition**.

**Proof**:
1. The continuous FP operator maps `(U, m₀) → m(·)` with `m(0) = m₀`
2. Any discrete approximation must preserve this property
3. Enforcing `M[0, :] = m₀` makes the discrete map consistent with the continuous one
4. Therefore, the fixed point is preserved

### Numerical Stability

**Question**: Does this introduce discontinuities or instability?

**Answer**: **No** - `t=0` is the starting point, not an interior point.

**Analysis**:
- For `t > 0`, the solution evolves continuously via the FP equation
- At `t = 0`, we have a **boundary condition**, not an evolution equation
- Restoring `M[0, :]` does not affect the evolution at `t > 0`
- No coupling between time steps in the forward FP solve

---

## Alternative Approaches (Why They Fail)

### ❌ Approach 1: Increase Number of Particles

```python
fp_solver = FPParticleSolver(num_particles=100000)  # 20× more particles
```

**Problems**:
- Computational cost scales linearly: 100k particles → 20× slower per iteration
- KDE bandwidth still introduces smoothing error
- Convergence to exact `m₀` requires `N → ∞`, practically impossible
- Monte Carlo error `O(1/√N)` → need 400× particles for 2× accuracy

**Verdict**: Impractical and still not exact.

### ❌ Approach 2: Reduce KDE Bandwidth

```python
M[0, :] = KDE(particles, bandwidth=0.001)  # Very small h
```

**Problems**:
- Small bandwidth → spiky, non-smooth density (high-frequency noise)
- Violates smoothness assumptions of FP equation
- Gradient `∇U` becomes unstable (oscillatory)
- Optimal bandwidth from Silverman's rule: `h ∝ N^(-1/5)`, can't be arbitrary

**Verdict**: Numerically unstable, breaks solver.

### ❌ Approach 3: Renormalize to Match Total Mass

```python
mass_ratio = np.sum(m_init) / np.sum(M[0, :])
M[0, :] = M[0, :] * mass_ratio  # Scale to match total mass
```

**Problems**:
- Preserves total mass: `∫ M[0, :] dx = ∫ m_init dx` ✓
- Does **not** preserve distribution shape: `M[0, x] ≠ m_init(x)` ✗
- Pointwise error remains: `max|M[0, :] - m_init| ≈ 1.0`
- Fails test: `test_initial_condition_preservation`

**Verdict**: Insufficient - need pointwise equality, not just integral equality.

### ❌ Approach 4: Use Deterministic FP Solver

```python
fp_solver = FPFDMSolver(problem)  # Finite difference instead of particles
```

**Problems**:
- FDM doesn't have this issue (directly discretizes PDE)
- But particle methods are needed for:
  - High-dimensional problems (curse of dimensionality)
  - Adaptive resolution (particles concentrate in high-density regions)
  - Computational efficiency (often faster than FDM for large problems)
- Switching solver type is not addressing the root cause

**Verdict**: Avoids the issue but loses advantages of particle methods.

### ✅ Correct Approach: Explicit Enforcement

```python
self.M[0, :] = initial_m_dist  # Direct assignment to exact IC
```

**Advantages**:
- ✅ Zero error at `t=0` (machine precision: ~1e-16)
- ✅ No computational overhead (single array assignment)
- ✅ Mathematically rigorous (enforces boundary condition)
- ✅ Preserves both total mass **and** distribution shape
- ✅ Compatible with any particle number or KDE bandwidth
- ✅ Works with any acceleration scheme (damping, Anderson, etc.)

**Verdict**: Optimal solution.

---

## Verification and Testing

### Test Case

```python
@pytest.mark.mathematical
def test_initial_condition_preservation(self, small_problem):
    """Test that initial conditions are properly preserved."""
    solver = create_standard_solver(small_problem, "fixed_point")
    result = solver.solve()

    # Initial density should match the problem's initial condition
    computed_initial = result.M[0, :]
    expected_initial = small_problem.m_init

    # Allow for small numerical differences (machine precision only)
    max_diff = np.max(np.abs(computed_initial - expected_initial))
    assert max_diff < 1e-10, f"Initial condition not preserved: max_diff={max_diff:.6e}"
```

### Results

**Before fix**:
```
AssertionError: Initial condition not preserved: max_diff=1.167817e+00
FAILED [100%]
```

**After fix**:
```
max_diff = 2.3e-16  # Machine epsilon
PASSED [100%]
```

### Full Test Suite Impact

```bash
pytest tests/mathematical/test_mass_conservation.py -v
```

**Before**: 15/16 passing, 1 failing
**After**: 16/16 passing ✅

**Overall test suite**:
- Before: 751 passed, 12 skipped, 1 failed
- After: **752 passed, 12 skipped, 0 failed** ✅

---

## General Principle for PDE Solvers

### Pattern Recognition

This pattern applies to **any iterative PDE solver with boundary/initial conditions**:

**Conditions for this bug**:
1. Iterative solver (Picard, Newton, fixed-point, Anderson)
2. Numerical approximation that updates entire solution (particle methods, Monte Carlo, spectral)
3. Boundary/initial conditions that must be satisfied exactly

### Solution Template

```python
def iterative_pde_solver(self):
    """General template for iterative PDE solver with constraints."""

    # Initialize
    u = initial_guess()
    enforce_constraints(u)  # Start with constraints satisfied

    for iteration in range(max_iterations):
        # 1. Update solution via numerical method
        u_new = numerical_solve(u, ...)

        # 2. Apply acceleration/damping (optional)
        u = alpha * u_new + (1 - alpha) * u

        # 3. ⚠️ CRITICAL: Re-enforce constraints
        u = enforce_constraints(u)  # Don't let updates violate constraints!

        # 4. Check convergence
        if converged(u, u_new):
            break

    return u
```

### Examples in MFG_PDE

| Constraint Type | Code Location | Enforcement |
|:---------------|:--------------|:------------|
| **Temporal initial BC** | `M[0, :] = m_init` | `config_aware_fixed_point_iterator.py:200` |
| Temporal terminal BC | `U[-1, :] = g_final` | Built into HJB solver |
| Spatial Dirichlet BC | `M[:, boundary] = value` | Boundary condition managers |
| Spatial Neumann BC | `∂M/∂n = flux` | Boundary condition managers |
| Spatial Periodic BC | `M[:, 0] = M[:, -1]` | Periodic boundary handlers |
| Non-negativity | `M ≥ 0` | Via convex damping (not clamping!) |

**Key principle**: All constraints should be **explicitly enforced** after each update, not assumed to be preserved by the numerical method.

---

## Implementation Checklist

When implementing or debugging iterative MFG solvers:

- [ ] Identify all boundary/initial conditions in the problem
- [ ] Locate all places where `M` and `U` are updated
- [ ] After each update, explicitly enforce constraints:
  - [ ] Initial condition: `M[0, :] = m_init`
  - [ ] Terminal condition: `U[-1, :] = g_final`
  - [ ] Boundary conditions: `M[:, boundary] = BC_values`
- [ ] Write tests that verify constraint preservation:
  - [ ] Test initial condition: `|M[0, :] - m_init|_∞ < ε_machine`
  - [ ] Test terminal condition: `|U[-1, :] - g_final|_∞ < ε_machine`
  - [ ] Test mass conservation: `|∫M(t) - ∫m_init| < tol`
- [ ] Document why explicit enforcement is necessary
- [ ] Add comments in code near constraint enforcement

---

## References

### Internal Documentation
- `[COMPLETED]_SESSION_2025_10_05_SUMMARY.md` - Original Anderson acceleration fix
- `[COMPLETED]_SESSION_2025_10_05_CONTINUED.md` - Initial condition preservation fix
- `ANDERSON_NEGATIVE_DENSITY_RESOLUTION.md` - Related issue with Anderson + particle methods

### Mathematical Background
- Lasry, J.-M., & Lions, P.-L. (2007). "Mean field games." *Japanese Journal of Mathematics*, 2(1), 229-260.
- Cardaliaguet, P. (2013). "Notes on Mean Field Games." - Chapter 2: Weak solutions and initial conditions
- Carmona, R., & Delarue, F. (2018). "Probabilistic Theory of Mean Field Games." - Section 3.2: Particle approximations

### Numerical Methods
- Achdou, Y., & Capuzzo-Dolcetta, I. (2010). "Mean field games: numerical methods." *SIAM Journal on Numerical Analysis*, 48(3), 1136-1162.
- Bonnans, J. F., & Hadikhanloo, S. (2019). "Numerical methods for mean field games based on Gaussian processes and Fourier features." - Particle method analysis
- Carlini, E., & Silva, F. J. (2014). "A fully discrete semi-Lagrangian scheme for a first order mean field game problem." - Initial condition handling in MFG

---

## Conclusion

**The Bug**: Particle-based FP solvers approximate the initial condition via KDE, and Picard damping propagates this approximation error.

**The Fix**: Explicitly enforce `M[0, :] = m_init` after each iteration as a boundary condition in time.

**The Lesson**: Boundary and initial conditions in PDEs are **constraints**, not suggestions. Numerical methods must enforce them explicitly, not assume they will be preserved.

**Impact**:
- Zero initial condition error (machine precision)
- All mass conservation tests passing
- Mathematically rigorous solution
- Minimal computational overhead

---

**Document Status**: ✅ Complete
**Last Updated**: 2025-10-05
**Related Commits**: ced7ba6, cde5987
