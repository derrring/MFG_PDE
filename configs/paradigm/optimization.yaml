# Base configuration for optimization methods
paradigm: optimization

# Optimization algorithm
algorithm:
  type: "gradient_descent"  # gradient_descent, newton, bfgs, primal_dual
  max_iterations: 1000
  tolerance: 1e-6

# Step size / learning rate
step_size:
  initial: 1e-3
  adaptive: true
  decay_rate: 0.95
  min_step_size: 1e-8

# Constraint handling
constraints:
  mass_conservation: true
  non_negativity: true
  boundary_conditions: true
  penalty_weight: 1e3

# Functional discretization
discretization:
  basis: "piecewise_linear"  # piecewise_linear, spline, fourier
  n_basis_functions: 1000
  regularization: 1e-6

# Line search
line_search:
  method: "armijo"
  c1: 1e-4
  max_ls_iterations: 20

# Convergence monitoring
monitoring:
  check_interval: 10
  save_iterates: false
  plot_convergence: true

# Solver-specific settings
solver_params:
  augmented_lagrangian:
    mu_initial: 1.0
    mu_factor: 10.0
    penalty_update_threshold: 0.1

  primal_dual:
    sigma: 0.1
    tau: 0.1
    theta: 1.0
